{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StreetEasy is New York Cityâ€™s leading real estate marketplace. You will be working with a\n",
    "# dataset that contains a sample of 3,540 rentals listings in Manhattan.\n",
    "# https://www.kaggle.com/zohaib30/streeteasy-dataset?select=manhattan.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for statistical tests\n",
    "import scipy\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "## for machine learning\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load your data, including testing/training split from Project 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3539, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan = pd.read_csv('manhattan.csv')\n",
    "manhattan.shape\n",
    "#below we can see our dataset has 3539 rows and 18 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2550\n",
      "1    11500\n",
      "2     4500\n",
      "3     4795\n",
      "4    17500\n",
      "Name: rent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = manhattan[\"rent\"]\n",
    "print(y.head()) # y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rental_id  bedrooms  bathrooms  size_sqft  min_to_subway  floor  \\\n",
      "0       1545       0.0          1        480              9    2.0   \n",
      "1       2472       2.0          2       2000              4    1.0   \n",
      "2       2919       1.0          1        916              2   51.0   \n",
      "3       2790       1.0          1        975              3    8.0   \n",
      "4       3946       2.0          2       4800              3    4.0   \n",
      "\n",
      "   building_age_yrs  no_fee  has_roofdeck  has_washer_dryer  has_doorman  \\\n",
      "0                17       1             1                 0            0   \n",
      "1                96       0             0                 0            0   \n",
      "2                29       0             1                 0            1   \n",
      "3                31       0             0                 0            1   \n",
      "4               136       0             0                 0            1   \n",
      "\n",
      "   has_elevator  has_dishwasher  has_patio  has_gym       neighborhood  \\\n",
      "0             1               1          0        1    Upper East Side   \n",
      "1             0               0          0        0  Greenwich Village   \n",
      "2             1               1          0        0            Midtown   \n",
      "3             1               1          0        1  Greenwich Village   \n",
      "4             1               1          0        1               Soho   \n",
      "\n",
      "     borough  \n",
      "0  Manhattan  \n",
      "1  Manhattan  \n",
      "2  Manhattan  \n",
      "3  Manhattan  \n",
      "4  Manhattan  \n"
     ]
    }
   ],
   "source": [
    "X = manhattan.drop([\"rent\"], axis=1)\n",
    "print(X.head()) # X variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2123, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #60% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1416, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape #40% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: (If not already done in Project 1) Prepare your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = X_train.copy() # copy of train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rental_id           0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "size_sqft           0\n",
       "min_to_subway       0\n",
       "floor               0\n",
       "building_age_yrs    0\n",
       "no_fee              0\n",
       "has_roofdeck        0\n",
       "has_washer_dryer    0\n",
       "has_doorman         0\n",
       "has_elevator        0\n",
       "has_dishwasher      0\n",
       "has_patio           0\n",
       "has_gym             0\n",
       "neighborhood        0\n",
       "borough             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cleaned.isnull().sum() # not missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2123, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm dropping the borough column since this dataset is entirely about Manhattan\n",
    "X_train_cleaned = X_train_cleaned.drop([\"borough\"], axis=1)\n",
    "X_train_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# onehot encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train_cat = X_train_cleaned['neighborhood'].values.reshape(-1,1)\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "X_train_cat_1hot = cat_encoder.fit_transform(X_train_cat)\n",
    "X_train_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cleaned = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rental_id           0\n",
       "bedrooms            0\n",
       "bathrooms           0\n",
       "size_sqft           0\n",
       "min_to_subway       0\n",
       "floor               0\n",
       "building_age_yrs    0\n",
       "no_fee              0\n",
       "has_roofdeck        0\n",
       "has_washer_dryer    0\n",
       "has_doorman         0\n",
       "has_elevator        0\n",
       "has_dishwasher      0\n",
       "has_patio           0\n",
       "has_gym             0\n",
       "neighborhood        0\n",
       "borough             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cleaned.isnull().sum() # not missisng values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1416, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm dropping the borough column since this dataset is entirely about Manhattan\n",
    "X_test_cleaned = X_test_cleaned.drop([\"borough\"], axis=1)\n",
    "X_test_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# onehot encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_test_cat = X_test_cleaned['neighborhood'].values.reshape(-1,1)\n",
    "\n",
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "X_test_cat_1hot = cat_encoder.fit_transform(X_test_cat)\n",
    "X_test_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 3: Examine your target attribute. Based on the data exploration you did in Project 1, confirm and examine the attribute you are going to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine and plot the distribution of the target attribute in your training set \n",
    "# (e.g., is it Gaussian, uniform, logarithmic). This will help you interpret the performance of \n",
    "# different algorithms on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.plot(kind='hist', bins=20, figsize=(12,6), facecolor='grey',edgecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_1hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat_1hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Selected two of the following supervised learning algorithms, ideally one from the first half of the list and one from the second half of the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train_cat_1hot, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_cat_1hot, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_cat_1hot, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train_cat_1hot, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train_cat_1hot, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test_cat_1hot, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
